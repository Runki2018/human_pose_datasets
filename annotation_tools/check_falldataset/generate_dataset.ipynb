{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成视频训练的训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "from pathlib import Path \n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pose_utils import vis_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int(x, y): \n",
    "    return int(x), int(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_of_bbox(bbox, keypoints):\n",
    "    \"\"\"判断是否有关键点超出边界框, 可视化发现超出边界框的关键点检测效果都比较差\"\"\"\n",
    "    x1, y1, w, h = bbox\n",
    "    x2, y2 = x1 + w, y1 + h \n",
    "    keypoints = np.array(keypoints).reshape((-1, 3))\n",
    "    x = keypoints[:, 0]\n",
    "    y = keypoints[:, 1]\n",
    "    return (x < x1).any() or (x > x2).any() or (y < y1).any() or (y > y2).any() \n",
    "\n",
    "def normalization(bbox, keypoints, img_h, img_w):\n",
    "    \"\"\"对边界框和关键点进行归一化\"\"\"\n",
    "    x1, y1, w, h = bbox\n",
    "    bbox = [x1/img_w, y1/img_h, w/img_w, h/img_h]\n",
    "    keypoints = np.array(keypoints).reshape((-1, 3))\n",
    "    keypoints[:, 0] /= img_w \n",
    "    keypoints[:, 1] /= img_h \n",
    "    keypoints = keypoints.flatten().tolist()\n",
    "    bbox = [round(i, 5) for i in bbox]\n",
    "    keypoints = [round(i, 5) for i in keypoints]\n",
    "    return bbox, keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(data_root, video_type='.avi'): \n",
    "    ann_path  = Path(data_root).joinpath(\"annotations\")\n",
    "    video_path = Path(data_root).joinpath(\"Videos\")\n",
    "    out_path = Path(data_root).joinpath(\"final_annotations\")\n",
    "\n",
    "    if not out_path.exists():\n",
    "        out_path.mkdir(mode=0o777, parents=True, exist_ok=True)\n",
    "        print(f\"annotation txt file saved to {str(out_path)}\")\n",
    "    else:\n",
    "        raise ValueError(f\"directory is allready exist => {str(out_path)}\")\n",
    "\n",
    "    try:\n",
    "        cv2.namedWindow(\"videos\", cv2.WINDOW_KEEPRATIO) \n",
    "        print(\"Press 'q' to exit this function.\") \n",
    "        for ann in ann_path.glob(\"*.json\"): \n",
    "            with ann.open('r') as fd: \n",
    "                json_dict = json.load(fd) \n",
    "\n",
    "            video_file = video_path.joinpath(ann.stem + video_type) \n",
    "            cap = cv2.VideoCapture(str(video_file)) \n",
    "            frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT) \n",
    "\n",
    "            # fall_direction 是跌倒方向，顺时针从1-8, 1是正北(默认值), 2是东北, 3是正东, .... \n",
    "            for ann_info in tqdm(json_dict[\"annotations\"], total=frame_count): \n",
    "                frame_id = int(ann_info['frame_id']) \n",
    "                bbox = ann_info['bbox']\n",
    "                keypoints = ann_info['keypoints']\n",
    "                label = ann_info['label']\n",
    "                fall_direction = ann_info['fall_direction']\n",
    "                width = ann_info['width']\n",
    "                height = ann_info['height']\n",
    "\n",
    "                if cap.isOpened() and frame_id < frame_count:  \n",
    "                    _, img = cap.read() \n",
    "\n",
    "                    if img is None or sum(bbox) == 0 or keypoints == []: \n",
    "                        continue \n",
    "\n",
    "                    # 可视化标注信息\n",
    "                    x1, y1, w, h = bbox\n",
    "                    x2, y2 = x1 + w, y1 + h\n",
    "                    img = vis_annotations(img, bbox, keypoints, size=1)\n",
    "                    # img = cv2.rectangle(img, _int(x1, y1), _int(x2, y2), color=(0, 255, 0), thickness=1)\n",
    "                    text = f\"{frame_id:2.0f}, {fall_direction:2.0f}\"\n",
    "                    img = cv2.putText(img, text, (14, 17), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  color=(0, 255, 0), thickness=1)\n",
    "                    if label == 0:\n",
    "                        img = cv2.putText(img, \"normal\", (14, 34), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  color=(0, 255, 0), thickness=1)\n",
    "                    elif label == 1:\n",
    "                        img = cv2.putText(img, \"falling\", (14, 34), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  color=(0, 255, 0), thickness=1)\n",
    "                    elif label == 2:\n",
    "                        img = cv2.putText(img, \"faint\", (14, 34), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  color=(0, 255, 0), thickness=1)\n",
    "                    else:\n",
    "                        raise ValueError(f\"{label=}, label should be 0, 1, or 2!\")  \n",
    "\n",
    "                    cv2.imshow(\"videos\", img)\n",
    "                    key = cv2.waitKey(1) \n",
    "                    if key & 0XFFFF == ord('q'): \n",
    "                        return \n",
    "\n",
    "                    # 保存标注文件\n",
    "                    if not out_of_bbox(bbox, keypoints):\n",
    "                        bbox, keypoints = normalization(bbox, keypoints, height, width) \n",
    "                        bbox = str(bbox).strip(\"[],\").replace(\",\", \"\")  # '[x1, y1, w, h]' -> \"x1 y1 w h\" \n",
    "                        keypoints = str(keypoints).strip(\"[],\").replace(\",\", \"\") \n",
    "                        out_file = out_path.joinpath(ann.stem + \".txt\") \n",
    "                        with out_file.open(\"a+\") as fd: \n",
    "                            # 每一帧的标注信息追加到生成文件中\n",
    "                            print(f\"{frame_id} {label} {width} {height} {bbox} {keypoints}\", file=fd) \n",
    "\n",
    "            cap.release()\n",
    "\n",
    "    except ValueError:\n",
    "        print(f\"value error: ann_file => {ann}\")\n",
    "\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置数据根目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = [\n",
    "    \"FallDataset_mp4/Coffee_room_01/\",\n",
    "    \"FallDataset_mp4/Coffee_room_02/\",\n",
    "    \"FallDataset_mp4/Home_01\",\n",
    "    \"FallDataset_mp4/Home_02/\",\n",
    "]\n",
    "for data_root in roots:\n",
    "    generate_dataset(data_root=data_root)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查生成帧的质量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_final_annotations(data_root):\n",
    "    ann_path  = Path(data_root).joinpath(\"final_annotations\")\n",
    "    video_path = Path(data_root).joinpath(\"Videos\")\n",
    "\n",
    "    try:\n",
    "        cv2.namedWindow(\"videos\", cv2.WINDOW_KEEPRATIO) \n",
    "        print(\"Press 'q' to exit this function.\") \n",
    "        for ann in ann_path.glob(\"*.txt\"): \n",
    "            txt_info = np.loadtxt(str(ann))   # 读入一个视频的标注文件\n",
    "\n",
    "            video_file = video_path.joinpath(ann.stem + \".avi\") \n",
    "            cap = cv2.VideoCapture(str(video_file)) \n",
    "            frame_count = len(txt_info)\n",
    "\n",
    "            # fall_direction 是跌倒方向，顺时针从1-8, 1是正北(默认值), 2是东北, 3是正东, .... \n",
    "            for line in tqdm(txt_info, total=frame_count): \n",
    "                frame_id = int(line[0])\n",
    "                label = int(line[1])\n",
    "                width, height = line[2:4]\n",
    "                bbox = line[4:8]\n",
    "                keypoints = line[8:]\n",
    "\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id) \n",
    "                _, img = cap.read() \n",
    "                if img is None: \n",
    "                    continue \n",
    "\n",
    "                # 缩放回原图大小\n",
    "                x1, y1, w, h = bbox \n",
    "                x1, y1, w, h = x1*width, y1*height, w*width, h*height \n",
    "                keypoints = keypoints.reshape((-1, 3)) \n",
    "                keypoints[:, 0] *= width \n",
    "                keypoints[:, 1] *= height \n",
    "\n",
    "                bbox = [x1, y1, w, h] \n",
    "                keypoints = keypoints.flatten().tolist() \n",
    "\n",
    "                # 可视化标注信息 \n",
    "                img = vis_annotations(img, bbox, keypoints, size=1) \n",
    "                text = f\"{frame_id:2.0f}, {label:2.0f}\" \n",
    "                img = cv2.putText(img, text, (14, 17), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  color=(0, 255, 0), thickness=1)\n",
    "                if label == 0: \n",
    "                    img = cv2.putText(img, \"normal\", (14, 34), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  color=(0, 255, 0), thickness=1)\n",
    "                elif label == 1: \n",
    "                    img = cv2.putText(img, \"falling\", (14, 34), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  color=(0, 255, 0), thickness=1)\n",
    "                elif label == 2: \n",
    "                    img = cv2.putText(img, \"faint\", (14, 34), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  color=(0, 255, 0), thickness=1)\n",
    "                else: \n",
    "                    raise ValueError(f\"{label=}, label should be 0, 1, or 2!\") \n",
    "\n",
    "                cv2.imshow(\"videos\", img)\n",
    "                key = cv2.waitKey(1) \n",
    "                if key & 0XFFFF == ord('q'): \n",
    "                    return \n",
    "\n",
    "            cap.release()\n",
    "    except ValueError:\n",
    "        print(f\"value error: ann_file => {ann}\")\n",
    "\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to exit this function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:01<00:00, 68.99it/s]\n",
      "100%|██████████| 344/344 [00:05<00:00, 65.95it/s]\n",
      "100%|██████████| 373/373 [00:05<00:00, 65.77it/s]\n",
      "100%|██████████| 178/178 [00:02<00:00, 65.97it/s]\n",
      "100%|██████████| 242/242 [00:03<00:00, 66.59it/s]\n",
      "100%|██████████| 137/137 [00:02<00:00, 66.50it/s]\n",
      "100%|██████████| 92/92 [00:01<00:00, 66.13it/s]\n",
      "100%|██████████| 168/168 [00:02<00:00, 66.09it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.82it/s]\n",
      "100%|██████████| 268/268 [00:04<00:00, 65.82it/s]\n",
      "100%|██████████| 212/212 [00:03<00:00, 65.74it/s]\n",
      "100%|██████████| 269/269 [00:04<00:00, 66.17it/s]\n",
      "100%|██████████| 443/443 [00:06<00:00, 66.18it/s]\n",
      "100%|██████████| 181/181 [00:02<00:00, 65.70it/s]\n",
      "100%|██████████| 224/224 [00:03<00:00, 65.87it/s]\n",
      "100%|██████████| 310/310 [00:04<00:00, 65.99it/s]\n",
      "100%|██████████| 265/265 [00:03<00:00, 66.25it/s]\n",
      " 50%|█████     | 131/261 [00:02<00:01, 65.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to exit this function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 56/424 [00:00<00:05, 67.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to exit this function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 95/171 [00:01<00:01, 66.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to exit this function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 42/295 [00:00<00:03, 70.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for data_root in roots:\n",
    "    check_final_annotations(data_root=data_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('p39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2977251e1b2ca22a3cfc09d5f408daba24a1809e852c29e73dfa9b1ba1933376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
